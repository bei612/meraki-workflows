#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´æµ‹è¯•æ‰€æœ‰14ä¸ªMeraki Temporal Workflow
åˆå¹¶äº†test_all_workflows.pyã€test_complex_workflows.pyã€test_concordia_workflows.py
ä¸€æ¬¡æ€§æµ‹è¯•æ‰€æœ‰åœºæ™¯å¹¶è¾“å‡ºå®Œæ•´çš„EChartsæ•°æ®

ç”¨æ³•ï¼š
  python test.py [org_id]

ç¤ºä¾‹ï¼š
  python test.py 850617379619606726
  python test.py  # ä½¿ç”¨é»˜è®¤org_id

æ³¨æ„ï¼šAPI Key ç”± merakiAPI.py è‡ªåŠ¨ä»ç¯å¢ƒå˜é‡è¯»å–
"""

import asyncio
import sys
import json
import uuid
import os
from datetime import datetime
from temporalio.client import Client

sys.path.append('.')

from concordia_workflows_echarts import (
    # åŸºç¡€å·¥ä½œæµ (10ä¸ª)
    DeviceStatusWorkflow, ConcordiaWorkflowInput,
    APDeviceQueryWorkflow, APDeviceQueryInput,
    ClientCountWorkflow,
    FirmwareSummaryWorkflow,
    LicenseDetailsWorkflow,
    DeviceInspectionWorkflow,
    FloorplanAPWorkflow, FloorplanAPInput,
    DeviceLocationWorkflow, DeviceLocationInput,
    LostDeviceTraceWorkflow, LostDeviceTraceInput,
    AlertsLogWorkflow,
    # å¤æ‚å·¥ä½œæµ (4ä¸ª)
    NetworkHealthAnalysisWorkflow, NetworkHealthAnalysisInput,
    SecurityPostureWorkflow, SecurityPostureInput,
    TroubleshootingWorkflow, TroubleshootingInput,
    CapacityPlanningWorkflow, CapacityPlanningInput,
)

# é»˜è®¤æµ‹è¯•å‚æ•°
DEFAULT_ORG_ID = "850617379619606726"  # Concordiaç»„ç»‡ID
TEMPORAL_HOST = "temporal:7233"
TEMPORAL_NAMESPACE = "avaca"
TASK_QUEUE = "meraki-workflows-queue"

def print_separator(title: str, char: str = "=", width: int = 80):
    """æ‰“å°åˆ†éš”ç¬¦"""
    print(f"\n{char * width}")
    print(f"{title:^{width}}")
    print(f"{char * width}")

def save_workflow_result(workflow_number: int, workflow_name: str, result, success: bool):
    """ä¿å­˜workflowç»“æœåˆ°JSONæ–‡ä»¶"""
    try:
        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs("workflow_results", exist_ok=True)
        
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®
        save_data = {
            "workflow_number": workflow_number,
            "workflow_name": workflow_name,
            "execution_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "success": success,
            "result": None,
            "error": None
        }
        
        if success and result:
            # å°†ç»“æœè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            if hasattr(result, '__dict__'):
                save_data["result"] = {
                    key: value for key, value in result.__dict__.items()
                    if not key.startswith('_')
                }
            else:
                save_data["result"] = result
        else:
            save_data["error"] = str(result) if result else "Unknown error"
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        filename = f"workflow_results/{workflow_number}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"   ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")
        
    except Exception as e:
        print(f"   âš ï¸  ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")

def print_workflow_result(result, workflow_name: str, workflow_number: int):
    """æ‰“å°å®Œæ•´çš„å·¥ä½œæµè¿”å›ç»“æœ"""
    print_separator(f"ğŸ” Workflow {workflow_number}: {workflow_name} - å®Œæ•´è¿”å›ç»“æœ", "=", 100)
    
    # å°†dataclassè½¬æ¢ä¸ºå­—å…¸
    if hasattr(result, '__dict__'):
        result_dict = {}
        for key, value in result.__dict__.items():
            result_dict[key] = value
    else:
        result_dict = result
    
    # æ‰“å°åŸºæœ¬ä¿¡æ¯
    print(f"ğŸ“Š å·¥ä½œæµåç§°: {workflow_name}")
    print(f"â° æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # åˆ¤æ–­æˆåŠŸçŠ¶æ€ï¼šæœ‰successå­—æ®µåˆ™ç”¨successå­—æ®µï¼Œå¦åˆ™æ£€æŸ¥æ˜¯å¦æœ‰echarts_data
    has_success_field = 'success' in result_dict
    is_success = result_dict.get('success', True) if has_success_field else bool(result_dict.get('echarts_data'))
    
    print(f"âœ… æ‰§è¡ŒçŠ¶æ€: {'æˆåŠŸ' if is_success else 'å¤±è´¥'}")
    
    if not is_success:
        print(f"âŒ é”™è¯¯ä¿¡æ¯: {result_dict.get('error_message', 'æœªçŸ¥é”™è¯¯')}")
        return
    
    # æ‰“å°ä¸šåŠ¡æ•°æ®
    print(f"\nğŸ“ˆ ä¸šåŠ¡æ•°æ®:")
    for key, value in result_dict.items():
        if key not in ['success', 'error_message', 'echarts_data']:
            if isinstance(value, (dict, list)):
                print(f"   {key}: {json.dumps(value, ensure_ascii=False, indent=2)[:200]}...")
            else:
                print(f"   {key}: {value}")
    
    # æ‰“å°EChartsæ•°æ®
    echarts_data = result_dict.get('echarts_data', [])
    print(f"\nğŸ¨ EChartså›¾è¡¨æ•°æ® ({len(echarts_data)}ä¸ªå›¾è¡¨):")
    
    if not echarts_data:
        print("   âš ï¸  æ— EChartsæ•°æ®")
        return
    
    for i, chart in enumerate(echarts_data, 1):
        print(f"\n   ğŸ“Š å›¾è¡¨ {i}:")
        if isinstance(chart, dict):
            # æå–å›¾è¡¨åŸºæœ¬ä¿¡æ¯
            chart_type = "æœªçŸ¥"
            chart_title = "æœªå‘½åå›¾è¡¨"
            
            if 'series' in chart and chart['series']:
                series = chart['series'][0] if isinstance(chart['series'], list) else chart['series']
                if isinstance(series, dict):
                    chart_type = series.get('type', 'æœªçŸ¥')
            
            if 'title' in chart:
                if isinstance(chart['title'], dict):
                    chart_title = chart['title'].get('text', 'æœªå‘½åå›¾è¡¨')
                else:
                    chart_title = str(chart['title'])
            
            print(f"      ç±»å‹: {chart_type}")
            print(f"      æ ‡é¢˜: {chart_title}")
            
            # æ‰“å°å®Œæ•´çš„EChartsé…ç½®ï¼ˆæ ¼å¼åŒ–ï¼‰
            print(f"      é…ç½®: {json.dumps(chart, ensure_ascii=False, indent=6)}")
        else:
            print(f"      æ•°æ®: {json.dumps(chart, ensure_ascii=False, indent=6)}")
    
    print(f"\n{'=' * 100}")

async def test_basic_workflows(client: Client, org_id: str):
    """æµ‹è¯•10ä¸ªåŸºç¡€å·¥ä½œæµ"""
    print_separator("ğŸ“Š åŸºç¡€å·¥ä½œæµæµ‹è¯• (10ä¸ª)", "=", 80)
    
    # å®šä¹‰åŸºç¡€å·¥ä½œæµæµ‹è¯•ç”¨ä¾‹
    basic_workflows = [
        {
            "name": "è®¾å¤‡çŠ¶æ€æŸ¥è¯¢",
            "workflow": DeviceStatusWorkflow,
            "input": ConcordiaWorkflowInput(org_id=org_id),
            "description": "2ä¸ªå›¾è¡¨ (é¥¼å›¾+æŸ±çŠ¶å›¾) - å·²å¢å¼º"
        },
        {
            "name": "APè®¾å¤‡æœç´¢",
            "workflow": APDeviceQueryWorkflow,
            "input": APDeviceQueryInput(org_id=org_id, search_keyword="MR"),
            "description": "è¡¨æ ¼+åœ°å›¾æ•£ç‚¹å›¾"
        },
        {
            "name": "å®¢æˆ·ç«¯ç»Ÿè®¡",
            "workflow": ClientCountWorkflow,
            "input": ConcordiaWorkflowInput(org_id=org_id),
            "description": "1ä¸ªæŸ±çŠ¶å›¾"
        },
        {
            "name": "å›ºä»¶ç‰ˆæœ¬æ±‡æ€»",
            "workflow": FirmwareSummaryWorkflow,
            "input": ConcordiaWorkflowInput(org_id=org_id),
            "description": "1ä¸ªå †å æŸ±çŠ¶å›¾"
        },
        {
            "name": "è®¸å¯è¯è¯¦æƒ…",
            "workflow": LicenseDetailsWorkflow,
            "input": ConcordiaWorkflowInput(org_id=org_id),
            "description": "1ä¸ªä»ªè¡¨ç›˜"
        },
        {
            "name": "è®¾å¤‡å·¡æ£€æŠ¥å‘Š",
            "workflow": DeviceInspectionWorkflow,
            "input": ConcordiaWorkflowInput(org_id=org_id),
            "description": "1ä¸ªé›·è¾¾å›¾"
        },
        {
            "name": "æ¥¼å±‚APåˆ†å¸ƒ",
            "workflow": FloorplanAPWorkflow,
            "input": FloorplanAPInput(org_id=org_id, floor_name="Floor"),
            "description": "1ä¸ªæ ‘å›¾"
        },
        {
            "name": "è®¾å¤‡ç‚¹ä½å›¾",
            "workflow": DeviceLocationWorkflow,
            "input": DeviceLocationInput(org_id=org_id, search_keyword="MR44"),
            "description": "1ä¸ªæ•£ç‚¹å›¾"
        },
        {
            "name": "ä¸¢å¤±è®¾å¤‡è¿½è¸ª",
            "workflow": LostDeviceTraceWorkflow,
            "input": LostDeviceTraceInput(org_id=org_id, client_mac="d0:88:0c:69:5c:0f"),
            "description": "1ä¸ªæ—¶é—´è½´å›¾"
        },
        {
            "name": "å‘Šè­¦æ—¥å¿—",
            "workflow": AlertsLogWorkflow,
            "input": ConcordiaWorkflowInput(org_id=org_id),
            "description": "1ä¸ªçƒ­åŠ›å›¾"
        }
    ]
    
    results = []
    
    for i, test_case in enumerate(basic_workflows, 1):
        print(f"\nğŸš€ æ‰§è¡ŒåŸºç¡€å·¥ä½œæµ {i}/10: {test_case['name']}")
        print(f"   ğŸ“Š é¢„æœŸè¾“å‡º: {test_case['description']}")
        
        try:
            # æ‰§è¡Œå·¥ä½œæµ
            workflow_id = f"test-basic-{i}-{uuid.uuid4().hex[:8]}"
            result = await client.execute_workflow(
                test_case['workflow'].run,
                test_case['input'],
                id=workflow_id,
                task_queue=TASK_QUEUE,
            )
            
            # æ‰“å°å®Œæ•´ç»“æœ
            print_workflow_result(result, test_case['name'], i)
            
            # ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
            save_workflow_result(i, test_case['name'], result, True)
            
            results.append({
                "workflow_number": i,
                "name": test_case['name'],
                "success": True,
                "echarts_count": len(result.echarts_data) if hasattr(result, 'echarts_data') and result.echarts_data else 0
            })
            
        except Exception as e:
            print(f"âŒ å·¥ä½œæµ {i} æ‰§è¡Œå¤±è´¥: {str(e)}")
            
            # ä¿å­˜é”™è¯¯ç»“æœåˆ°JSONæ–‡ä»¶
            save_workflow_result(i, test_case['name'], str(e), False)
            
            results.append({
                "workflow_number": i,
                "name": test_case['name'],
                "success": False,
                "error": str(e)
            })
    
    return results

async def test_complex_workflows(client: Client, org_id: str):
    """æµ‹è¯•4ä¸ªå¤æ‚å·¥ä½œæµ"""
    print_separator("ğŸš€ å¤æ‚å¤šActivityç»„åˆå·¥ä½œæµæµ‹è¯• (4ä¸ª)", "=", 80)
    
    # å®šä¹‰å¤æ‚å·¥ä½œæµæµ‹è¯•ç”¨ä¾‹
    complex_workflows = [
        {
            "name": "ç½‘ç»œå¥åº·å…¨æ™¯åˆ†æ",
            "workflow": NetworkHealthAnalysisWorkflow,
            "input": NetworkHealthAnalysisInput(org_id=org_id),
            "description": "4ä¸ªå›¾è¡¨ (é¥¼å›¾+æŸ±çŠ¶å›¾+æ•£ç‚¹å›¾+ä»ªè¡¨ç›˜)"
        },
        {
            "name": "å®‰å…¨æ€åŠ¿æ„ŸçŸ¥åˆ†æ",
            "workflow": SecurityPostureWorkflow,
            "input": SecurityPostureInput(org_id=org_id),
            "description": "4ä¸ªå›¾è¡¨ (æ ‘å›¾+é›·è¾¾å›¾+çƒ­åŠ›å›¾+æŸ±çŠ¶å›¾)"
        },
        {
            "name": "è¿ç»´æ•…éšœè¯Šæ–­",
            "workflow": TroubleshootingWorkflow,
            "input": TroubleshootingInput(org_id=org_id),
            "description": "2ä¸ªå›¾è¡¨ (é›·è¾¾å›¾+æ—¶é—´è½´å›¾)"
        },
        {
            "name": "å®¹é‡è§„åˆ’åˆ†æ",
            "workflow": CapacityPlanningWorkflow,
            "input": CapacityPlanningInput(org_id=org_id, forecast_days=30),
            "description": "4ä¸ªå›¾è¡¨ (ä»ªè¡¨ç›˜+æ—¶é—´è½´+å †å æŸ±çŠ¶å›¾+é¥¼å›¾)"
        }
    ]
    
    results = []
    
    for i, test_case in enumerate(complex_workflows, 11):
        print(f"\nğŸš€ æ‰§è¡Œå¤æ‚å·¥ä½œæµ {i}/16: {test_case['name']}")
        print(f"   ğŸ“Š é¢„æœŸè¾“å‡º: {test_case['description']}")
        print(f"   ğŸ”„ ç‰¹æ€§: å¤šActivityå¹¶å‘æ‰§è¡Œï¼Œé«˜çº§æ•°æ®åˆ†æ")
        
        try:
            # æ‰§è¡Œå·¥ä½œæµ
            workflow_id = f"test-complex-{i}-{uuid.uuid4().hex[:8]}"
            result = await client.execute_workflow(
                test_case['workflow'].run,
                test_case['input'],
                id=workflow_id,
                task_queue=TASK_QUEUE,
            )
            
            # æ‰“å°å®Œæ•´ç»“æœ
            print_workflow_result(result, test_case['name'], i)
            
            # ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
            save_workflow_result(i, test_case['name'], result, True)
            
            results.append({
                "workflow_number": i,
                "name": test_case['name'],
                "success": True,
                "echarts_count": len(result.echarts_data) if hasattr(result, 'echarts_data') and result.echarts_data else 0
            })
            
        except Exception as e:
            print(f"âŒ å·¥ä½œæµ {i} æ‰§è¡Œå¤±è´¥: {str(e)}")
            
            # ä¿å­˜é”™è¯¯ç»“æœåˆ°JSONæ–‡ä»¶
            save_workflow_result(i, test_case['name'], str(e), False)
            
            results.append({
                "workflow_number": i,
                "name": test_case['name'],
                "success": False,
                "error": str(e)
            })
    
    return results

def print_final_statistics(basic_results: list, complex_results: list):
    """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
    print_separator("ğŸ“Š æœ€ç»ˆæµ‹è¯•ç»Ÿè®¡æŠ¥å‘Š", "=", 100)
    
    all_results = basic_results + complex_results
    total_workflows = len(all_results)
    successful_workflows = len([r for r in all_results if r.get('success', False)])
    failed_workflows = total_workflows - successful_workflows
    
    print(f"\nğŸ¯ **æ€»ä½“ç»Ÿè®¡**:")
    print(f"   æ€»å·¥ä½œæµæ•°é‡: {total_workflows}")
    print(f"   æˆåŠŸæ‰§è¡Œ: {successful_workflows}")
    print(f"   æ‰§è¡Œå¤±è´¥: {failed_workflows}")
    print(f"   æˆåŠŸç‡: {(successful_workflows/total_workflows*100):.1f}%")
    
    print(f"\nğŸ“Š **åŸºç¡€å·¥ä½œæµç»Ÿè®¡ (1-10)**:")
    basic_success = len([r for r in basic_results if r.get('success', False)])
    print(f"   æˆåŠŸ: {basic_success}/10")
    print(f"   å¤±è´¥: {10-basic_success}/10")
    
    print(f"\nğŸš€ **å¤æ‚å·¥ä½œæµç»Ÿè®¡ (11-14)**:")
    complex_success = len([r for r in complex_results if r.get('success', False)])
    print(f"   æˆåŠŸ: {complex_success}/4")
    print(f"   å¤±è´¥: {4-complex_success}/4")
    
    print(f"\nğŸ¨ **EChartså›¾è¡¨ç»Ÿè®¡**:")
    total_charts = sum(r.get('echarts_count', 0) for r in all_results if r.get('success', False))
    print(f"   æ€»å›¾è¡¨æ•°: {total_charts}")
    
    # è¯¦ç»†çš„å·¥ä½œæµç»“æœ
    print(f"\nğŸ“‹ **è¯¦ç»†ç»“æœåˆ—è¡¨**:")
    print(f"{'åºå·':<4} {'å·¥ä½œæµåç§°':<25} {'çŠ¶æ€':<6} {'å›¾è¡¨æ•°':<8} {'ç±»å‹':<8}")
    print("-" * 70)
    
    for result in all_results:
        status = "âœ…æˆåŠŸ" if result.get('success', False) else "âŒå¤±è´¥"
        charts = result.get('echarts_count', 0) if result.get('success', False) else 0
        wf_type = "åŸºç¡€" if result['workflow_number'] <= 10 else "å¤æ‚"
        
        print(f"{result['workflow_number']:<4} {result['name'][:24]:<25} {status:<6} {charts:<8} {wf_type:<8}")
    
    # å¤±è´¥çš„å·¥ä½œæµè¯¦æƒ…
    failed_results = [r for r in all_results if not r.get('success', False)]
    if failed_results:
        print(f"\nâŒ **å¤±è´¥å·¥ä½œæµè¯¦æƒ…**:")
        for result in failed_results:
            print(f"   {result['workflow_number']}. {result['name']}: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    print(f"\nğŸ—ï¸ **ç³»ç»Ÿæ¶æ„ç‰¹æ€§**:")
    print(f"   ğŸ“Š åŸºç¡€å·¥ä½œæµ: 10ä¸ª (1-3ä¸ªAPIè°ƒç”¨ï¼Œ1-2ä¸ªEChartså›¾è¡¨)")
    print(f"   ğŸš€ å¤æ‚å·¥ä½œæµ: 4ä¸ª (4-5ä¸ªAPIå¹¶å‘ï¼Œ2-4ä¸ªEChartså›¾è¡¨)")
    print(f"   ğŸ¨ å›¾è¡¨ä¸»é¢˜: ç»Ÿä¸€æš—ç´«è‰²ä¸»é¢˜")
    print(f"   ğŸ”§ APIè¦†ç›–: 64ä¸ªMeraki APIæ–¹æ³•")
    print(f"   ğŸ“ˆ å›¾è¡¨ç±»å‹: 10+ç§EChartså›¾è¡¨ç±»å‹")
    
    print(f"\nğŸ’¼ **ä¸šåŠ¡ä»·å€¼**:")
    print(f"   ğŸ¢ ç½‘ç»œç®¡ç†: å…¨æ–¹ä½ç½‘ç»œè®¾å¤‡å’Œå®¢æˆ·ç«¯ç®¡ç†")
    print(f"   ğŸ”’ å®‰å…¨ç›‘æ§: å¤šç»´åº¦å®‰å…¨æ€åŠ¿æ„ŸçŸ¥")
    print(f"   ğŸ”§ è¿ç»´æ”¯æŒ: æ™ºèƒ½æ•…éšœè¯Šæ–­å’Œæ€§èƒ½ä¼˜åŒ–")
    print(f"   ğŸ“Š å†³ç­–æ”¯æŒ: å®¹é‡è§„åˆ’å’Œç½‘ç»œå¥åº·åˆ†æ")
    print(f"   ğŸ“ˆ æ•°æ®å¯è§†åŒ–: ä¸°å¯Œçš„EChartså›¾è¡¨å±•ç¤º")
    
    if failed_workflows == 0:
        print(f"\nğŸ‰ **æ‰€æœ‰14ä¸ªå·¥ä½œæµæµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼**")
    else:
        print(f"\nâš ï¸  **æœ‰{failed_workflows}ä¸ªå·¥ä½œæµæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³é…ç½®**")
    
    return failed_workflows == 0

async def main():
    """ä¸»å‡½æ•°"""
    # è·å–ç»„ç»‡ID
    org_id = sys.argv[1] if len(sys.argv) > 1 else DEFAULT_ORG_ID
    
    print_separator("ğŸš€ Meraki Temporal Workflow å®Œæ•´æµ‹è¯•ç³»ç»Ÿ", "=", 100)
    print(f"ğŸ“‹ æµ‹è¯•ç»„ç»‡ID: {org_id}")
    print(f"â° æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ”§ TemporalæœåŠ¡: {TEMPORAL_HOST}")
    print(f"ğŸ“¦ å‘½åç©ºé—´: {TEMPORAL_NAMESPACE}")
    print(f"ğŸ¯ ä»»åŠ¡é˜Ÿåˆ—: {TASK_QUEUE}")
    print(f"ğŸ’¾ ç»“æœä¿å­˜: workflow_results/1-14.json")
    
    try:
        # è¿æ¥TemporalæœåŠ¡
        print(f"\nğŸ”Œ è¿æ¥TemporalæœåŠ¡...")
        client = await Client.connect(TEMPORAL_HOST, namespace=TEMPORAL_NAMESPACE)
        print(f"âœ… æˆåŠŸè¿æ¥åˆ°TemporalæœåŠ¡")
        
        # æµ‹è¯•åŸºç¡€å·¥ä½œæµ
        basic_results = await test_basic_workflows(client, org_id)
        
        # æµ‹è¯•å¤æ‚å·¥ä½œæµ
        complex_results = await test_complex_workflows(client, org_id)
        
        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        success = print_final_statistics(basic_results, complex_results)
        
        # é€€å‡º
        sys.exit(0 if success else 1)
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
